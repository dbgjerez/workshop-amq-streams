= Data streaming
include::_attributes.adoc[]

We talked about Kafka topic concept in a previous session. Now it's time to send and receive data from a topic. 

We must understand the consumer, producer and consumer groups to discuss the streaming data concept. 

[#producersandconsumers]
== Producers and consumers

The following image shows a topic structure:

image::topic-structure.png[Topic structure]

A **producer** is an application that sends data to a topic. If a topic has more than one **partition**, Kafka balances it along the partitions. Also, each partition is replicated along the Kafka brokers depending on the replica factor number, although our application always writes the data in the leader partition. 

image::topic-producer.png[Topic producer]

The **consumer** is the application that receives the data from a topic partition. More than one application forms a **consumer group**.

image::topic-consumer-group.png[Topic consumer group]

A consumer group works as a unique functional unit, so the **offset** is unique for each. 

The **offset** is a point of the latest element consumed by a consumer group. One advantage of using Kafka is that if you modify the offset, the data can be reprocessed. 

These concepts are essential to have an optimized Kafka architecture. If we think of an optimal architecture, the ideal scenario would be to have the same number of partitions in a topic as applications in each consumer group. 

If we have more applications than partitions, some applications will do nothing. Oppositely, if we have more partitions than applications, the process won't be parallelized. 

The following image shows two optimized consumer groups with different offsets. 

image::topic-two-consumer-group.png[Topic two consumer groups]

[#simple]
== Simple data
Once, we've yet learned about Kafka concepts, it's time to play with it. 

We can work with many data types in Kafka, in this example, we're going to show the simplest way to work with simple text data. 

To do it, we need an application. We can use a lot of languages and frameworks, in this case, we're going to use Quarkus and Java 17. 

Also, we'll deploy a topic and users.

[#sendsimpledata]
=== Send plain text

The application that sends the data to Kafka is: https://github.com/dbgjerez/quarkus-kafka/tree/main/simple-kafka-producer



[#receivesimpledata]
=== Receive plain text
// TODO

[#json]
== JSON data
// TODO write about a JSON strcutre data

[#sendjson]
=== Send JSON
// TODO 

[#receivejson]
=== Receive JSON
// TODO

[#avro]
== Avro schemes
// TODO write about a JSON strcutre data

* xref:04-data.adoc[4. Data]
** xref:04-data.adoc#simple[Simple data]
*** xref:04-data.adoc#sendsimpledata[Send plain text]
*** xref:04-data.adoc#receivesimpledata[Receive plain text]
** xref:04-data.adoc#json[JSON]
*** xref:04-data.adoc#sendjson[Send JSON]
*** xref:04-data.adoc#receivejson[Receive JSON]
** xref:04-data.adoc#avro[Avro scheme]