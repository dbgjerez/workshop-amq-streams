= Data streaming
include::_attributes.adoc[]

We talked about Kafka topic concept in a previous session. Now it's time to send and receive data from a topic. 

We must understand the consumer, producer and consumer groups to discuss the streaming data concept. 

[#producersandconsumers]
== Producers and consumers

The following image shows a topic structure:

image::topic-structure.png[Topic structure]

A **producer** is an application that sends data to a topic. If a topic has more than one **partition**, Kafka balances it along the partitions. Also, each partition is replicated along the Kafka brokers depending on the replica factor number, although our application always writes the data in the leader partition. 

image::topic-producer.png[Topic producer]

The **consumer** is the application that receives the data from a topic partition. More than one application forms a **consumer group**.

image::topic-consumer-group.png[Topic consumer group]

A consumer group works as a unique functional unit, so the **offset** is unique for each. 

The **offset** is a point of the latest element consumed by a consumer group. One advantage of using Kafka is that if you modify the offset, the data can be reprocessed. 

[#simple]
== Simple data
// TODO write about a simple text for example

[#sendsimpledata]
=== Send plain text
// TODO write about how send plain text and the quarkus examples in another repository

[#receivesimpledata]
=== Receive plain text
// TODO

[#json]
== JSON data
// TODO write about a JSON strcutre data

[#sendjson]
=== Send JSON
// TODO 

[#receivejson]
=== Receive JSON
// TODO

[#avro]
== Avro schemes
// TODO write about a JSON strcutre data

* xref:04-data.adoc[4. Data]
** xref:04-data.adoc#simple[Simple data]
*** xref:04-data.adoc#sendsimpledata[Send plain text]
*** xref:04-data.adoc#receivesimpledata[Receive plain text]
** xref:04-data.adoc#json[JSON]
*** xref:04-data.adoc#sendjson[Send JSON]
*** xref:04-data.adoc#receivejson[Receive JSON]
** xref:04-data.adoc#avro[Avro scheme]